---
title: "NLP with Large Language Models" 
subtitle: ""
author: "Alex van Vorstenbosch"
footer: "NLP with LLMs"
title-slide-attributes:
    data-background-image: "./figures/llm_for_nlp.png"
    data-background-opacity: "0.5"
---

## NLP-lifecycle on it's head

\
Regular ML:\
Problem &rarr; Idea &rarr; Gather data &rarr; Train Model &rarr; Evaluate Model &rarr;\
<span class="highlighted-text">Repeat if neccessary</span> &rarr; deploy\
Duration: Months\
\
\

Prompting workflow:\
Problem &rarr; Idea &rarr; Gather (less) data &rarr; Finetune prompt &rarr; Evaluate Model &rarr;\
<span class="highlighted-text">Repeat if neccessary</span> &rarr; already deployed\
Duration: Days

## NLP-tasks

:::{.nonincremental}
- Sentiment analysis
- Named entity recognition
- Natural language generation
- Speech recognition
- Speech synthesis
- Question answering
- Machine translation
- Summarisation
- Classification
- Topic modeling
- etc...
:::

## Jack of all trades, master of none...
- LLMs are great at a wide range of tasks...
- ... but they aren't state-of-the-art for specific tasks
- *Might also be skewed due to allignment problem between benchmarks and human-eval in some metrics.*

## ... Except for QA and Reasoning
- They are [SOTA](https://arxiv.org/pdf/2305.10403v3.pdf) for <span class="highlighted-text">Question Answering</span> and <span class="highlighted-text">Reasoning</span> 
- Might fit into the Jack of all trades analogy.
- *"Best student in class on average, but not the best in class in any single subject"*

## Papers with Code
- For an overview of the current best model for your task:\
[paperswithcode/Natural-Language-Processing](https://paperswithcode.com/area/natural-language-processing)

## Semantic versus Pragmatic

:::{.columns}

:::{.column width="40%"}
- Semantic meaning: Literal
- Pragmatic meaning: Context dependent

:::{.fragment}
> *"Wow, you really are an expert"*
:::
- Semantic: Compliment
- Pragmatic: Sarcastic, Compliment, etc.

:::

:::{.column width="60%"}
![[ChatGPT: Jack of all trades, master of none](https://www.sciencedirect.com/science/article/pii/S156625352300177X)](./figures/chatgpt-versus-sota.jpg)

:::
:::

## Performance for Aspect Based Sentiment Analysis
- Aspect Based Sentiment Analysis. 
    - The service was great but the food was terrible
        - service: positive
        - food: negative

![[Is ChatGPT a Good Sentiment Analyzer? A Preliminary Study](https://arxiv.org/pdf/2304.04339.pdf)](./figures/absc-chatgpt.png)

## Performance for Aspect Based Sentiment Analysis

:::{.nonincremental}
- Aspect Based Sentiment Analysis. 
    - The service was great but the food was terrible
        - service: positive
        - food: negative
:::

![[Is ChatGPT a Good Sentiment Analyzer? A Preliminary Study](https://arxiv.org/pdf/2304.04339.pdf)](./figures/ChatGPT-generalizes-better.png)

## ChatGPT for summarization {auto-animate="true"}

::: {data-id="fig1"}
![[Extractive Summarization via ChatGPT for Faithful Summary Generation](https://arxiv.org/pdf/2304.04193.pdf)\
[G-EVAL: NLG Evaluation using GPT-4 with Better Human Alignment](https://arxiv.org/pdf/2303.16634.pdf)](./figures/chatgpt-for-summarization.png)
:::

## ChatGPT for evaluating summarization {auto-animate="true"}

::: {data-id="fig1"}
![[G-EVAL: NLG Evaluation using GPT-4 with Better Human Alignment](https://arxiv.org/pdf/2303.16634.pdf)](./figures/G-eval.png){width="1000px" height="auto"}
:::

## ChatGPT for evaluating summarization {auto-animate="true"}

::: {data-id="fig1"}
![[G-EVAL: NLG Evaluation using GPT-4 with Better Human Alignment](https://arxiv.org/pdf/2303.16634.pdf)](./figures/llms-all-the-way-down.webp)
:::

## What if your model is not performing up to your standard?

- You can only have so many few-shot examples for it to be economical
- OpenAI offer the option to finetune your model
- This will update parameter weights to better fit your usecase
- This will result in a 'new' model you can call from the API in the future 

## Usecases of Finetuning 

- Improving reliability at producing your desired output
- Correcting failures to follow instructions for more complex prompts
- Performing a new skill or task thatâ€™s hard to articulate in a prompt
- Show don't tell: It allows for more concise prompts as you can shown it what answers you expect

![](./figures/Finetuning.png)

## What will Finetuning give you?

- Higher quality results than prompting with examples.
- Ability to train on more examples than can fit in a prompt.
- Saving tokens due to shorter prompts.
- Lower latency requests due to shorter prompts.
![](./figures/Finetuning.png)


## What will Finetuning give you?

- &uArr; Finetuned models will have improved performance in the specific domain you train on.
- &dArr; But reduced general performance.

## How does finetuning work

- [OpenAI finetuning guide](https://platform.openai.com/docs/guides/fine-tuning/use-a-fine-tuned-model)
    - Start with 50 examples
    - Check if this provides any improvements
    - Make sure you have an evaluation set
    - *"Every doubling of the data you may expect a similair improvement gain"*
- Finetuned models currently cost 3x of regular models
    - If this saves you 10+ few-shot examples it's quickly worth it. 

## The optimization flow

![[OpenAI: A Survey of Techniques for Maximizing LLM Performance](https://www.youtube.com/watch?v=ahnGLM-RC1Y&t=2266s&ab_channel=OpenAI)](./figures/Model-optimization.png)
