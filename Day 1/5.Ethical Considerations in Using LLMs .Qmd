---
title: "Ethical Considerations in Using LLMs"
subtitle: "*The good, the Bad, and the Ugly*"
author: "Alex van Vorstenbosch"
footer: "Ethics and LLMs"
title-slide-attributes:
  data-background-image: "./figures/llms-and-ethics.webp"
  data-background-opacity: "0.5"

date: "11-17-2023"
---

## Overview
\
__Disclaimer__\
I don't claim to have the answers.\
It is important to be aware of these topics.\
Form your own opinions, and openly discuss these issues.

## Overview
- <span class="highlighted-text">Biases and Misinformation</span>
- The Dark Side of LLMs
- Privacy and Legal Challenges

# Biases and Misinformation

## Biases
- LLMs can strengthen negative stereotypes
- LLMs can might strengten the views of users via confirmation bias:
  - LLMs have a tendency to agree with the user
  - People have a tendency to think that 'models' are objective and speak the 'truth'
- LLMs are 'skewed' to the trainingset majority:
  - English Western views 

## Hallucinating false information
- What are <span class="highlighted-text">Hallucinations</span>? 
  - It's when LLMs generates incorrect, nonsensical, or unverifiable information presented as fact.
  - Might also be answers that are not supported by the provided context
  - Can be hard to spot as the model is a great 'bluffer'
    - Doesn't know that the information is wrong
    - self-reflection does help however

## Hallucinating false information
- What are <span class="highlighted-text">Hallucinations</span>? 
  - It's when LLMs generates incorrect, nonsensical, or unverifiable information presented as fact.

::: {.columns}

::: {.column width="50%"}
 <iframe src="https://chat.openai.com/share/e8826676-81ad-40b9-a9ad-a27dc22f9151" class="iframe-chatgpt"></iframe>

:::

::: {.column width="50%"}
 <iframe src="https://chat.openai.com/share/49872740-604f-4b27-a844-002eff6743a9" class="iframe-chatgpt"></iframe>

:::

:::

# The Dark Side of LLMs(?)

## Moderation of your GPT application with the OpenAI moderation API
- Make sure no `bad` content is processed via your API-key
- The moderation endpoint is free to use when monitoring the inputs and outputs of OpenAI APIs. 
- [OpenAI Moderation API](https://platform.openai.com/docs/guides/moderation/overview)
```{.python}
moderation_resp = openai.Moderation.create(input="Am I breaking any of the rules here?")
``` 
## Copyright issues and LLMs
- Can the output be copywrighted?
- Can they be trained on copywrighted materials?
- Can you claim contain generated by LLMs is infringing copywright

## Privacy issues and LLMs
- Can companies train LLMs on (scraped) private data without consent?
  - What if LLMs memorise private data?
- How can we mitigate inference of private information by LLMs?
  - [https://llm-privacy.org/](https://llm-privacy.org/)
- How can we trust third-parties with our proprietary/private information?
  - This will be discussed further on Day 2

## Transparency issues of LLMs
- How can we trust models that are "black boxes"?
  - Especially if aren't even sure what these models look like or how they were trained?
- How can these models be used if they can generate 'hallucinations' at any point?
- How can we prevent the use of LLMs for unsuited usecases?

## Misuse of LLMs
- How can we prevent the automated generation of misinformation at scale?
- How can we prevent the use of these techniques for spam, identity fraud, and worse?
- Who should decide what misuse of LLMs means?

## Climate impact of large language models
- These models are very compute intensive:
  - In the training process
  - But also during inference!
- How can we justify this (inefficient) use of technology?

## Training the model via RLHF

::: {.columns}

::: {.column width="50%"}

- Low-wage workers in Kenia were paid to help collect data for the 'moderation' tool: 
  - Traumatising work
:::

::: {.column width="50%"}
![](./figures/times-sama-2dollar.png)
[Time: Exclusive: OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic]("https://time.com/6247678/openai-chatgpt-kenya-workers/")
:::

:::

## Use of LLMs for essays, homework, etc. cannot be reliably detected.
::: {.columns}

::: {.column width="50%"}
- AI-detectors don't work, which is creating serious issues for students.
![](./figures/turnitinGPTconstitution.jpg)
:::

::: {.column width="50%"}
- AI-detectors don't work, which is disrupting how homework is given and made.
![](./figures/howtogetdetectedbyturnitin.webp)
:::

:::

## Propositions